# Angorange 2019
# Quick and Dirty script to generate lexicon in the needed format

# trim_lexicon : keeps only words within a given range length
# group_by_anagrams : groups words by exact anagrams (same length, same letters)

import pickle

# Opens text file src_name containing one word per line
# and writes in dst_name the ones containing between min_letter and max_letter

def trim_lexicon(src_name, dst_name, min_letter, max_letter):

    print("Generate:", dst_name)
    print("Keep only word from", min_letter, "letters to", max_letter, "letters")

    srcFile = open(src_name, "r")
    allLines = srcFile.readlines()
    srcFile.close()

    dstFile = open(dst_name, "w")

    stats = [0] * (max_letter + 1)
    total = 0

    for line in allLines:
        word_length = len(line) - 1 # removing return line character '\n'
        
        if word_length >= min_letter and word_length <= max_letter:
            stats[word_length] += 1
            total += 1
            dstFile.write(line)

    dstFile.close()

    print("Total word:", total)

    for index in range (min_letter, max_letter + 1):
        print(index, "letters words:", stats[index])



def hash_word(word): 
    result = "" 

    return result.join(sorted(word))

# Open text file src_name containing one word per line
# groups word by anagrams in a dict (same letters, same length)
# save the dict to dst_name


def group_by_anagrams(src_name, dst_name):

    print("Generate:", dst_name)

    srcFile = open(src_name, "r")
    allLines = srcFile.readlines()
    srcFile.close()

    d = dict()

    for line in allLines:
        word = line.strip()
        key = hash_word(word)

        if key not in d: 
            d[key] = [] # Creates the entry if it does not exist yet
        d[key].append(word)
    
    dstFile = open(dst_name,"wb")
    pickle.dump(d, dstFile, pickle.HIGHEST_PROTOCOL)
    dstFile.close()

    print ("Number of entries:", len(d))
    print ("Number of words:", len(allLines))


def create_JDM_files():
    minLength = 3
    maxLength = 7

    path = "../../data/"
    all_words_file = path + "lexique_fr.txt"
    words_3_7_file = path + "lexicon_fr_3_7.txt"
    anagrams_dict_file = path + "anagrams_fr_3_7.bin"

    # Generates "lexicon_fr_3_7.txt" from file "lexique_fr.txt" generated by wouf's script
    # It keeps only words having between 3 and 7 letters (included)
    trim_lexicon(all_words_file, words_3_7_file, minLength, maxLength)
    print("-----")

    # Groups words by anagrams (words with same length and same letters)
    group_by_anagrams(words_3_7_file, anagrams_dict_file)
    print("-----")

create_JDM_files()